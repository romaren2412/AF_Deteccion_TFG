import numpy as np
import torch
from sklearn.metrics import roc_auc_score


def simple_mean(old_gradients, param_list, net, lr, b, hvp=None):
    """
        :param old_gradients: lista de gradientes calculados polos dispositivos
        :param param_list: lista de par√°metros da rede
        :param net: modelo global
        :param lr: taxa de aprendizaxe
        :param b: lista de dispositivos byzantinos
        :param hvp: hessian-vector product
    """
    # HAI HESSIANA CALCULADA --> C√ÅLCULO DE DISTANCIA
    if hvp is not None:
        pred_grad = []

        # Predici√≥n dos gradientes --> gradiente vello + hvp
        for i in range(len(old_gradients)):
            pred_grad.append(old_gradients[i] + hvp)

        # Vector de predici√≥ns
        pred = np.zeros(len(old_gradients))
        # b: lista de dispositivos byzantinos --> Os b vectores son "an√≥malos"
        pred[b] = 1

        # Se non hai clientes byzantinos ou todos son byzantinos, calcular distancia directamente
        if len(b) == 0 or len(b) == len(old_gradients):
            # DISTANCIA ENTRE GRADIENTES PREDITOS E NOVOS
            distancia = torch.norm(torch.cat(pred_grad, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()

        # C√ÅLCULO DE DISTANCIAS E √ÅREA BAIXO A CURVA ROC:
        # M√âTRICA PARA AVALIAR A CALIDADE DUN MODELO DE CLASIFICACI√ìN BINARIA
        else:
            # DISTANCIA A: ENTRE GRADIENTES VELLOS E NOVOS
            distancia = torch.norm(torch.cat(old_gradients, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
            auc1 = roc_auc_score(pred, distancia)

            # DISTANCIA B: DISTANCIA ENTRE GRADIENTES PREDITOS E NOVOS
            distancia = torch.norm(torch.cat(pred_grad, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
            auc2 = roc_auc_score(pred, distancia)
            print("Detection AUC: %0.4f; Detection AUC: %0.4f" % (auc1, auc2))

        # NORMALIZACI√ìN DE DISTANCIAS
        distancia = distancia / np.sum(distancia)
    else:
        distancia = None

    # C√ÅLCULO DA MEDIA DOS GRADIENTES
    mean_nd = torch.mean(torch.cat(param_list, dim=1), dim=-1, keepdim=True)

    idx = 0
    # Actualizaci√≥n dos par√°metros
    for j, param in enumerate(net.parameters()):
        if param.requires_grad:
            param.data = param.data - lr * mean_nd[idx:(idx + param.data.numel())].reshape(param.data.shape)
            idx = idx + param.data.numel()

    return mean_nd, distancia


"""
Trimmed-Mean first sorts the values of the corresponding coordinates in the clients‚Äô model updates.
After removing the largest and the smallest ùëò values, Trimmed-Mean calculates the average of the
remaining ùëõ ‚àí 2ùëò values
"""


def trim(old_gradients, param_list, net, lr, b, hvp=None):
    """
    :param old_gradients: lista de gradientes calculados polos dispositivos
    :param param_list: lista de par√°metros da rede
    :param net: modelo global
    :param lr: taxa de aprendizaxe
    :param b: lista de dispositivos byzantinos
    :param hvp: hessian-vector product
    """
    if hvp is not None:
        pred_grad = []
        for i in range(len(old_gradients)):
            pred_grad.append(old_gradients[i] + hvp)
        pred = np.zeros(len(old_gradients))
        pred[b] = 1
        if len(b) == 0 or len(b) == len(old_gradients):
            distancia = torch.norm(torch.cat(pred_grad, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
        else:
            distancia = torch.norm(torch.cat(old_gradients, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
            auc1 = roc_auc_score(pred, distancia)
            distancia = torch.norm(torch.cat(pred_grad, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
            auc2 = roc_auc_score(pred, distancia)
            print("Detection AUC: %0.4f; Detection AUC: %0.4f" % (auc1, auc2))
        distance = distancia / np.sum(distancia)
    else:
        distance = None

    # Trimmed-Mean calcula a media dos valores restantes ùëõ ‚àí 2ùëò, despois de eliminar os ùëò valores m√°ximos e m√≠nimos
    # 1. Ordenar
    sorted_tensor, _ = torch.sort(torch.cat(param_list, dim=1), dim=-1)

    # 2. Podar
    n = len(param_list)  # n√∫mero de dispositivos
    m = n - len(b) * 2  # ùëõ ‚àí 2ùëò values restantes (ùëò valores m√°ximos e m√≠nimos eliminados)

    # 3. media dos valores restantes ùëõ ‚àí 2ùëò
    # Dentro dos dispositivos benignos, qu√©danse cos valores entre b e b+m
    benign_workers = np.setdiff1d(np.arange(n), b)
    trim_benign = benign_workers[:m]
    trim_tensor = torch.mean(sorted_tensor[:, trim_benign], dim=-1, keepdim=True)

    # Actualizar modelo global
    idx = 0
    for param in net.parameters():
        if param.requires_grad:
            param.data = param.data - lr * trim_tensor[idx:(idx + param.data.numel())].reshape(param.data.shape)
            idx += param.data.numel()

    return trim_tensor, distance


"""
Median calculates the median value of the corresponding coordinates in all model updates and treats it as
the corresponding coordinate of the aggregated model update.
"""


def median(old_gradients, param_list, net, lr, b, hvp=None):
    """
        :param old_gradients: lista de gradientes calculados polos dispositivos
        :param param_list: lista de par√°metros da rede
        :param net: modelo global
        :param lr: taxa de aprendizaxe
        :param b: n√∫mero de dispositivos byzantinos
        :param hvp: hessian-vector product
        """
    if hvp is not None:
        pred_grad = []
        for i in range(len(old_gradients)):
            pred_grad.append(old_gradients[i] + hvp)
        pred = np.zeros(len(old_gradients))
        pred[b] = 1
        if len(b) == 0 or len(b) == len(old_gradients):
            distancia = torch.norm(torch.cat(pred_grad, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
        else:
            distancia = torch.norm(torch.cat(old_gradients, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
            auc1 = roc_auc_score(pred, distancia)
            distancia = torch.norm(torch.cat(pred_grad, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
            auc2 = roc_auc_score(pred, distancia)
            print("Detection AUC: %0.4f; Detection AUC: %0.4f" % (auc1, auc2))
        distance = distancia / np.sum(distancia)
    else:
        distance = None

    # C√ÅLCULO DA MEDIANA
    if len(param_list) % 2 == 1:
        # Se hai un n√∫mero impar de dispositivos, a mediana √© o valor central
        median_nd = torch.sort(torch.cat(param_list, dim=1), dim=-1)[0][:, len(param_list) // 2]
        median_nd = median_nd.view(-1, 1)
    else:
        # Se hai un n√∫mero par de dispositivos, a mediana √© a media dos dous valores centrais
        median_nd = torch.sort(torch.cat(param_list, dim=1), dim=-1)[0][:, len(param_list) // 2: len(param_list) // 2 + 1].mean(dim=-1, keepdim=True)

    # Actualizar modelo global
    idx = 0
    for param in net.parameters():
        if param.requires_grad:
            param.data = param.data - lr * median_nd[idx:(idx + param.data.numel())].reshape(param.data.shape)
            idx += param.data.numel()

    return median_nd, distance


"""
Krum tries to find a single model update among the clients‚Äô model updates
as the aggregated model update in each iteration.
The chosen model update is the one with the closest
Euclidean distances to the nearest ùëõ ‚àí ùëò ‚àí 2 model updates.
"""


def score(gradient, v, f):
    num_neighbours = v.shape[1] - 2 - f
    sorted_distance, _ = torch.sort(torch.sum((v - gradient) ** 2, dim=0))
    return torch.sum(sorted_distance[1:(1 + num_neighbours)]).item()


def krum(old_gradients, param_list, net, lr, b, hvp=None):
    """
        :param old_gradients: lista de gradientes calculados polos dispositivos
        :param param_list: lista de par√°metros da rede
        :param net: modelo global
        :param lr: taxa de aprendizaxe
        :param b: n√∫mero de dispositivos byzantinos
        :param hvp: hessian-vector product
    """
    if hvp is not None:
        pred_grad = []
        for i in range(len(old_gradients)):
            pred_grad.append(old_gradients[i] + hvp)
        pred = np.zeros(len(old_gradients))
        pred[b] = 1
        if len(b) == 0:
            distancia = torch.norm(torch.cat(pred_grad, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
        else:
            distancia = torch.norm(torch.cat(old_gradients, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
            auc1 = roc_auc_score(pred, distancia)
            distancia = torch.norm(torch.cat(pred_grad, dim=1) - torch.cat(param_list, dim=1), dim=0).cpu().numpy()
            auc2 = roc_auc_score(pred, distancia)
            print("Detection AUC: %0.4f; Detection AUC: %0.4f" % (auc1, auc2))
        distance = distancia / np.sum(distancia)
    else:
        distance = None

    # ATOPAR O MELLOR GRADIENTE
    num_params = len(param_list)  # n√∫mero de dispositivos
    q = len(b)  # n√∫mero de dispositivos byzantinos
    if num_params <= 2:
        # Se non hai suficientes clientes, escoller un de forma aleatoria
        random_idx = np.random.choice(num_params)
        krum_tensor = param_list[random_idx].view(-1, 1)
    else:
        if num_params - q - 2 <= 0:  # n-k-2 <= 0 (se non hai polo menos 3 dispositivos benignos)
            q = num_params - 3  # q = n-3    (asumir que hai n-3 dispositivos byzantinos)

        # Calcular a distancia de cada gradiente ao resto dos gradientes
        v = torch.cat(param_list, dim=1)
        scores = torch.tensor([score(gradient, v, q) for gradient in param_list])

        # Escoller o gradiente coa menor distancia
        min_idx = int(scores.argmin(dim=0).item())
        krum_tensor = param_list[min_idx].view(-1, 1)

    # Actualizar o modelo global
    idx = 0
    for param in net.parameters():
        if param.requires_grad:
            param.data = param.data - lr * krum_tensor[idx:(idx + param.data.numel())].reshape(param.data.shape)
            idx += param.data.numel()

    return krum_tensor, distance
